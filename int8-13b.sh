python int8-13b.py --all-files --model llama-2-13b-chat-hf --load-in-8bit --data-dir "./annotation/query/" --save-dir "./quantization/llama-2-13b-chat-hf_INT8/"