# #!/bin/bash
export CUDA_VISIBLE_DEVICES=0
python main.py --all-files --model llama-2-13b-chat-hf